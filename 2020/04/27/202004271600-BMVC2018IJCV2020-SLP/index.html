<!DOCTYPE html>
<html lang="zh-hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhang-mohole.github.io","root":"/","scheme":"Gemini","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="SignLanguage Production Using Neural Machine Translation And Generative Adervsarial Networksnote at: 2020-04-27 16:00 labels: SLP conf: BMVC 2020 author: Stephanie Stoll, Necati Cihan Camgoz, (Centre">
<meta property="og:type" content="article">
<meta property="og:title" content="202004271600-WACV2018IJCV2020-SLP">
<meta property="og:url" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="SignLanguage Production Using Neural Machine Translation And Generative Adervsarial Networksnote at: 2020-04-27 16:00 labels: SLP conf: BMVC 2020 author: Stephanie Stoll, Necati Cihan Camgoz, (Centre">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-framework.png">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-align-neck.jpeg">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-factor.jpeg">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-skeletal-norm.jpg">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-gloss-representation.jpeg">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-encoder-decoder.png">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-loss.jpeg">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-framework.png">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-motion-graph.png">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-GAN.png">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-result1.png">
<meta property="og:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-result2.png">
<meta property="article:published_time" content="2020-04-27T08:00:23.000Z">
<meta property="article:modified_time" content="2020-05-11T16:05:47.861Z">
<meta property="article:author" content="Mohole Zhang">
<meta property="article:tag" content="SLT">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-framework.png">

<link rel="canonical" href="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>202004271600-WACV2018IJCV2020-SLP | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-hans">
    <link itemprop="mainEntityOfPage" href="https://zhang-mohole.github.io/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mohole Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          202004271600-WACV2018IJCV2020-SLP
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-27 16:00:23" itemprop="dateCreated datePublished" datetime="2020-04-27T16:00:23+08:00">2020-04-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-12 00:05:47" itemprop="dateModified" datetime="2020-05-12T00:05:47+08:00">2020-05-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sign-language/" itemprop="url" rel="index"><span itemprop="name">sign language</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="SignLanguage-Production-Using-Neural-Machine-Translation-And-Generative-Adervsarial-Networks"><a href="#SignLanguage-Production-Using-Neural-Machine-Translation-And-Generative-Adervsarial-Networks" class="headerlink" title="SignLanguage Production Using Neural Machine Translation And Generative Adervsarial Networks"></a>SignLanguage Production Using Neural Machine Translation And Generative Adervsarial Networks</h1><p><em>note at:</em> 2020-04-27 16:00</p>
<p><em>labels:</em> SLP</p>
<p><strong>conf:</strong> BMVC 2020</p>
<p><strong>author:</strong> Stephanie Stoll, Necati Cihan Camgoz, (Centre for Vision, Speech and Signal Processing University of Surrey)</p>
<h2 id="framework"><a href="#framework" class="headerlink" title="framework"></a>framework</h2><p><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-framework.png" alt="first NN based SLP framework"></p>
<a id="more"></a>
<h2 id="problems-to-be-solved"><a href="#problems-to-be-solved" class="headerlink" title="problems to be solved"></a>problems to be solved</h2><ul>
<li>之前SLP相关的工作大多是基于avatar的</li>
<li>一种方式是利用motion capture data来驱动avatar做出相应的动作，这种方式需要建立一个pre-recorded phrases相应的动作驱动表示，这种基于motion capture的方式的代价很高</li>
<li>另一种方式的思路是：把text翻译为对应的sign gloss(一个手语词汇的表示)，然后建立该 gloss entity的parametric representation，例如驱动avatar用到的hand shape和motion。这种方式的问题在于：1、这种直接逐词翻译是不符合手语的语法的；2、对于手语中的其他表示信息，这里忽略了（如表情之类的）；最终最好也就能得到粗略的表示，更甚只能得到错误的手语结果。</li>
</ul>
<h2 id="methods-proposed"><a href="#methods-proposed" class="headerlink" title="methods proposed"></a>methods proposed</h2><p>本文是第一次使用DL的方式来解决text2real-person-sign-video任务的，第一次定义了这个问题，并提出了自己的解决方法。利用SOTA的NMT模型来进行text2glosses翻译，建立glosses到对应upper body pose sequence的lookup table获得gloss到pose sequence的映射，最终通过一个VAE+DCGAN模型逐帧生成相应的sign video。</p>
<blockquote>
<p>method details</p>
</blockquote>
<ul>
<li><p>text to gloss translation</p>
<ul>
<li>这里使用了经典的encoder-decoder with Luong attention</li>
<li>具体的网络结构是，encoder decoder使用了4层GRU，隐层特征单元为1000维</li>
<li>Adam, lr:1e-5 30 epochs, dropout:0.2</li>
</ul>
</li>
<li><p>gloss to skeletal mapping</p>
<ul>
<li>这里的mapping是从一个gloss sentence映射到一个skeletal sequence</li>
<li>其中关键点是利用openpose提取的，这里只用了upper body部分(10个)，并没有使用hand pose</li>
<li>对skeletal的处理：<ul>
<li>把reference image中的pose作为ref，先把sequence中所有的skeletal对齐到跟ref的neck相同位置（先用ref的neck坐标减去输入的neck坐标得到neck的偏差，然后将输入的skeletal坐标都加上这个数，这样就得到了输入skeletal平移到ref位置的坐标）<img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-align-neck.jpeg" alt="first step"></li>
<li>根据肩膀宽度来计算输入skeletal跟ref skeletal之间的比例因子f（ref的左右肩膀坐标差，除以输入skeletal的左右肩膀坐标差）<img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-factor.jpeg" alt="second step"></li>
<li>最后，利用经过neck关键点对齐的skeletal以及比例因子f，计算normalized skeletal。（1、用第一步计算得到的输入经过平移得到的neck对齐后的结果减去ref的neck坐标，这样得到了该skeletal各关键点相对于neck的相对坐标，然后该相对坐标乘以f得到跟ref同比例的skeletal相对坐标，最后加上ref的neck坐标变成跟red的neck位置相同的绝对坐标）<img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-skeletal-norm.jpg" alt="third step"></li>
<li><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-gloss-representation.jpeg" alt="representative mean sequence for a gloss"></li>
</ul>
</li>
</ul>
</li>
<li><p>pose conditioned sign generation network</p>
<ul>
<li>image encoder and generator<ul>
<li>输入是ref image(128x128x3) + upper body skeletal对应的heatmap(128<em>128</em>10)；输出是跟该skeletal对应的image(128<em>128</em>3)</li>
<li>encoder由conv和FC组成，5次conv，每次conv前先将feature maps跟resize到相应大小的heatmap进行concat；</li>
<li>decoder的结构跟encoder结构对称，不过没有FC层，使用deconv，每次deconv之前跟encoder相应位置的特征之间有residual link</li>
<li><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-encoder-decoder.png" alt="encoder decoder network details"></li>
</ul>
</li>
<li>discriminator<ul>
<li>其详细结构论文中没有提及，只说了输入输出</li>
<li>input：1、G得到的生成图像/GT图像；2、skeletal pose heatmap；3、base pose input image（ref image，用于在训练multi signer时鉴别G得到的人跟ref是否是一个）</li>
</ul>
</li>
<li>loss<ul>
<li><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/bmvc-loss.jpeg" alt="loss"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="discussions"><a href="#discussions" class="headerlink" title="discussions"></a>discussions</h2><p>这篇文章看来是开山之作了，虽然存在一些问题，但是无疑已经把这半年想要抢第一个挖坑机会的想法给覆灭了<del>~</del></p>
<ul>
<li>其中存在的问题主要在于，这里的pose作者仅仅使用了upper body，对于hand pose这一很重要的信号，并没有在GAN网络中用到，这里必然导致最终生成的质量不好，语义表达一定是不太好的。</li>
<li>再者，在gloss到pose sequence这一步，作者给出的方法是给一个lookup table来进行mapping，这里方法部分介绍的不多，但从其中的意思可以看出是用一个从GT skeletal中计算得到的向量来做key，从而在得到一个loss后利用这样一种representation来进行映射得到pose sequence。首先这种预定义的库的确是一种可行的思路，但是这种思路确实是很strate forward，应该有更好的可以end2end的方法。</li>
</ul>
<h2 id="available-datasets"><a href="#available-datasets" class="headerlink" title="available datasets"></a>available datasets</h2><p>the SMILE Sign Language Assessment Dataset: Smile swiss german sign language dataset, 02 2018.(去官方网页看并没有一个下载链接，连数据都看不到，可以发邮件问问)</p>
<h2 id="some-inspirations"><a href="#some-inspirations" class="headerlink" title="some inspirations"></a>some inspirations</h2><h1 id="Text2Sign-Towards-Sign-Language-Production-Using-Neural-Machine-Translation-and-Generative-Adversarial-Networks"><a href="#Text2Sign-Towards-Sign-Language-Production-Using-Neural-Machine-Translation-and-Generative-Adversarial-Networks" class="headerlink" title="Text2Sign: Towards Sign Language Production Using Neural Machine Translation and Generative Adversarial Networks"></a>Text2Sign: Towards Sign Language Production Using Neural Machine Translation and Generative Adversarial Networks</h1><p><em>note at:</em> 202005112307</p>
<p><em>labels:</em> SLP</p>
<p><strong>journal:</strong> IJCV 2020</p>
<p><strong>author:</strong> Stephanie Stoll , Necati Cihan Camgoz</p>
<p><strong>no codes available</strong></p>
<h2 id="framework-1"><a href="#framework-1" class="headerlink" title="framework"></a>framework</h2><p><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-framework.png" alt="IJCV 2020 SLP framework"></p>
<h2 id="methods-proposed-1"><a href="#methods-proposed-1" class="headerlink" title="methods proposed"></a>methods proposed</h2><p>本文是在上面BMVC2018那篇工作的基础上进行了更深入的研究得到的工作，总体上来说比BMVC那篇更为科学，也更系统完整。</p>
<blockquote>
<p>method 概览</p>
</blockquote>
<p>主体过程仍然是 text-&gt;gloss-&gt;pose seq-&gt;video<br>不过跟BMVC那篇不同的是，gloss-&gt;pose seq这个过程，不再是一个简单的map table,而是建立了一个motion graph，这个是本文的关键创新点。pose seq-&gt;video 这个过程在具体方法上也有所改变，但是这里的创新相对不大，主要是利用了18年（本文投稿的时候）的pix2pixHD网络替换了BMVC那篇中自己搭建的baseline网络。</p>
<p>本文主要流程是，</p>
<ul>
<li>1、利用encoder-decoder-luong attention的NMT网络实现text2gloss；</li>
<li>2、在gloss的概率空间上建立motion graph（MG），MG的节点是包含了一系列原始motion pose(s)的数据，这个可以看做是先验概率p(x_i)，而MG的边代表从前一个顶点到下一个顶点的后验概率p(x_j | x_i), NMT decoder的输出可以看做这里的后验概率p(x_j | x_i), 这中间还会有个Y_ij的过程，这个就是在两个motion之间进行smoothing 插值，使得前一个节点到下一个节点的motion不会出现肉眼可见的跳跃；</li>
<li>3、有了pose seq，利用pix2pixHD网络即可获得跟目标pose一致的图像输出</li>
</ul>
<blockquote>
<p>method details</p>
</blockquote>
<h3 id="text-gt-gloss"><a href="#text-gt-gloss" class="headerlink" title="text-&gt;gloss"></a>text-&gt;gloss</h3><p>这里利用了一个GRU + luong attention的结构，encoder decoder都是4层单向GRU，都有一个embedding layer,decoder在最后有个projection layer<br>（这里，对于decoder的具体输出，还需要进一步深入解读，是获得了gloss还是仅用gloss作为训练时的监督信号，实际上不需要进行softmax来进行到gloss的映射而是仅通过projection layer获得gloss概率）</p>
<h3 id="motion-graph-text-gt-pose-seq"><a href="#motion-graph-text-gt-pose-seq" class="headerlink" title="motion graph (text-&gt;pose seq)"></a>motion graph (text-&gt;pose seq)</h3><p>这个地方，motion graph的建立是一个重难点</p>
<p>主要是graph节点的建立。</p>
<ul>
<li>节点建立<ul>
<li>首先要提取视频中的pose，然后利用一定的算法找到视频中的关键帧，利用关键帧把视频分割成gloss，而其他帧的pose跟所属gloss一起作为原始动作（motion primitives），即一个节点</li>
<li>这里，具体的算法作者并没有给出，可以发邮件问一问</li>
</ul>
</li>
<li>有向边建立<ul>
<li>有向边的理论意义就如上文，就是一个从x_i到x_j的转化概率，类似马尔科夫随机场，从一个状态到另一个状态的变换。这里用后验概率p(x_j | x_i)来表示。</li>
<li>在实际建模中，作者利用NMT网络中decoder当前时刻t的输出概率作为p(x_t | x_t-1)，从而得到有向图的边。</li>
<li>有了节点和节点之间的边的建模，也就有了MG。</li>
</ul>
</li>
</ul>
<p><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-motion-graph.png" alt="motion graph"></p>
<h3 id="pose-gt-image"><a href="#pose-gt-image" class="headerlink" title="pose-&gt;image"></a>pose-&gt;image</h3><p><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-GAN.png" alt="GAN based pose2image generation"></p>
<h2 id="results"><a href="#results" class="headerlink" title="results"></a>results</h2><p><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-result1.png" alt="result1"></p>
<p><img src="/2020/04/27/202004271600-BMVC2018IJCV2020-SLP/ijcv-result2.png" alt="result2"></p>
<h2 id="discussions-1"><a href="#discussions-1" class="headerlink" title="discussions"></a>discussions</h2><h2 id="available-datasets-1"><a href="#available-datasets-1" class="headerlink" title="available datasets"></a>available datasets</h2><h2 id="some-inspirations-1"><a href="#some-inspirations-1" class="headerlink" title="some inspirations"></a>some inspirations</h2>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/SLT/" rel="tag"># SLT</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/04/26/202004261703-ARXIV2020-SLT2/" rel="prev" title="202004261703-ARXIV2020-SLT2">
      <i class="fa fa-chevron-left"></i> 202004261703-ARXIV2020-SLT2
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/29/202004080031-ECCV2018-2-5D-heatmap/" rel="next" title="202004080031-ECCV2018-2.5D_heatmap">
      202004080031-ECCV2018-2.5D_heatmap <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#SignLanguage-Production-Using-Neural-Machine-Translation-And-Generative-Adervsarial-Networks"><span class="nav-number">1.</span> <span class="nav-text">SignLanguage Production Using Neural Machine Translation And Generative Adervsarial Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#framework"><span class="nav-number">1.1.</span> <span class="nav-text">framework</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#problems-to-be-solved"><span class="nav-number">1.2.</span> <span class="nav-text">problems to be solved</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#methods-proposed"><span class="nav-number">1.3.</span> <span class="nav-text">methods proposed</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#discussions"><span class="nav-number">1.4.</span> <span class="nav-text">discussions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#available-datasets"><span class="nav-number">1.5.</span> <span class="nav-text">available datasets</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#some-inspirations"><span class="nav-number">1.6.</span> <span class="nav-text">some inspirations</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Text2Sign-Towards-Sign-Language-Production-Using-Neural-Machine-Translation-and-Generative-Adversarial-Networks"><span class="nav-number">2.</span> <span class="nav-text">Text2Sign: Towards Sign Language Production Using Neural Machine Translation and Generative Adversarial Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#framework-1"><span class="nav-number">2.1.</span> <span class="nav-text">framework</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#methods-proposed-1"><span class="nav-number">2.2.</span> <span class="nav-text">methods proposed</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#text-gt-gloss"><span class="nav-number">2.2.1.</span> <span class="nav-text">text-&gt;gloss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#motion-graph-text-gt-pose-seq"><span class="nav-number">2.2.2.</span> <span class="nav-text">motion graph (text-&gt;pose seq)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pose-gt-image"><span class="nav-number">2.2.3.</span> <span class="nav-text">pose-&gt;image</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#results"><span class="nav-number">2.3.</span> <span class="nav-text">results</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#discussions-1"><span class="nav-number">2.4.</span> <span class="nav-text">discussions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#available-datasets-1"><span class="nav-number">2.5.</span> <span class="nav-text">available datasets</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#some-inspirations-1"><span class="nav-number">2.6.</span> <span class="nav-text">some inspirations</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Mohole Zhang"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Mohole Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mohole Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.2
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
